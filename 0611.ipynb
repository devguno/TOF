{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 cohort에 포함되지 않는 person_id를 가진 행이 제거된 파일이 'cohort_ecg_final.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "cohort_file_path = 'cohort_final2.csv'\n",
    "tofdrug_file_path = 'tof_ecg.csv'\n",
    "output_file_path = 'cohort_ecg_final.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "cohort_df = pd.read_csv(cohort_file_path)\n",
    "tofdrug_df = pd.read_csv(tofdrug_file_path)\n",
    "\n",
    "# person_id 추출\n",
    "cohort_person_ids = set(cohort_df['person_id'])\n",
    "tofdrug_person_ids = set(tofdrug_df['person_id'])\n",
    "\n",
    "# cohort에 포함되지 않는 person_id 확인\n",
    "non_cohort_person_ids = tofdrug_person_ids - cohort_person_ids\n",
    "\n",
    "# 포함되지 않는 person_id를 가진 행 제거\n",
    "filtered_tofdrug_df = tofdrug_df[~tofdrug_df['person_id'].isin(non_cohort_person_ids)]\n",
    "\n",
    "# 결과 저장\n",
    "filtered_tofdrug_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"최종 cohort에 포함되지 않는 person_id를 가진 행이 제거된 파일이 '{output_file_path}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1447"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_tofdrug_df['person_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플링된 데이터가 'cohort_final_ecg2_sampled.csv' 파일에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_35972\\769683850.py:7: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "file_path = 'tofdrug2_drug_filtered.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 무작위로 200개의 행 샘플링\n",
    "df_sampled = df.sample(n=200, random_state=42)  # random_state를 설정하여 결과를 재현 가능하게 할 수 있습니다.\n",
    "\n",
    "# 샘플링된 데이터를 새로운 CSV 파일로 저장\n",
    "df_sampled.to_csv('cohort_final_drug_sample.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"샘플링된 데이터가 'cohort_final_ecg2_sampled.csv' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_35972\\1246462216.py:7: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카테고리가 할당된 데이터가 'tofdrug2_drug_filtered_categorized.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "file_path = 'tofdrug2_drug_filtered.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 카테고리 매핑 함수 정의\n",
    "def map_drug_category(value):\n",
    "    diuretics = ['FRS4', 'SRN2', 'HCT']\n",
    "    raas = ['ENL', 'ENL5', 'LST100', 'LST25']\n",
    "    beta_blocker = ['CVD3', 'CVD6', 'CVD1', 'CVD', 'CVDS8', 'CVDS16', 'CVDS64', 'CVDS32']\n",
    "    antiplatelet = ['ASAT1', 'ASAE', 'ASA500', 'CPD', 'CPDN']\n",
    "    anticoagulation = ['WFR2', 'WFR5']\n",
    "    etc = ['SCBVS50', 'SCBVS100', 'SCBVS200', 'TVT15', 'TVT30', 'DPGZ']\n",
    "    class_i = ['FCND50', 'QND', 'MXLT', 'LDC2I', 'LDC1I', 'LDC2I5']\n",
    "    class_ii = ['NDL', 'ATN', 'ATN2', 'PPN1', 'PPN4', 'PPNS', 'MTP', 'BSPL', 'BSPL1K', 'BSPL2', 'BSPL10', 'CVD3', 'CVD6', 'CVD1', 'CVD', 'CVDS8', 'CVDS16', 'CVDS64', 'CVDS32']\n",
    "    class_iii = ['AMO', 'AMOI', 'STL4']\n",
    "    class_iv = ['VRP18', 'VRP4', 'VRP8', 'VRPI', 'DTA3IR', 'DTA3', 'DTA9', 'DTAI', 'DTA18']\n",
    "    miscellaneous = ['DGXL', 'DGX25', 'DGXI', 'ADN90I', 'ADNI']\n",
    "    \n",
    "    if value in diuretics:\n",
    "        return 'diuretics'\n",
    "    elif value in raas:\n",
    "        return 'raas'\n",
    "    elif value in beta_blocker:\n",
    "        return 'beta_blocker'\n",
    "    elif value in antiplatelet:\n",
    "        return 'antiplatelet'\n",
    "    elif value in anticoagulation:\n",
    "        return 'anticoagulation'\n",
    "    elif value in etc:\n",
    "        return 'etc'\n",
    "    elif value in class_i:\n",
    "        return 'class_i'\n",
    "    elif value in class_ii:\n",
    "        return 'class_ii'\n",
    "    elif value in class_iii:\n",
    "        return 'class_iii'\n",
    "    elif value in class_iv:\n",
    "        return 'class_iv'\n",
    "    elif value in miscellaneous:\n",
    "        return 'miscellaneous'\n",
    "    else:\n",
    "        return None  # 해당하지 않는 약물은 None\n",
    "\n",
    "# 새로운 컬럼 'drug_category' 추가\n",
    "df['drug_category'] = df['drug_source_value'].apply(map_drug_category)\n",
    "\n",
    "# None 값인 행 삭제 (카테고리에 해당하지 않는 약물)\n",
    "df_filtered = df.dropna(subset=['drug_category'])\n",
    "\n",
    "# 결과 저장\n",
    "output_file_path = 'tofdrug2_drug_filtered_categorized.csv'\n",
    "df_filtered.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"카테고리가 할당된 데이터가 '{output_file_path}' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계속 복용한 데이터가 'medication_continued.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "file_path = 'tofdrug2_drug_filtered_categorized.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 날짜 컬럼을 datetime 형식으로 변환\n",
    "df['drug_exposure_start_date'] = pd.to_datetime(df['drug_exposure_start_date'])\n",
    "df['drug_exposure_end_date'] = pd.to_datetime(df['drug_exposure_end_date'])\n",
    "\n",
    "# 데이터프레임을 person_id와 drug_exposure_start_date 기준으로 정렬\n",
    "df = df.sort_values(by=['person_id', 'drug_exposure_start_date'])\n",
    "\n",
    "# 복용 중단 기간 계산\n",
    "df['next_start_date'] = df.groupby('person_id')['drug_exposure_start_date'].shift(-1)\n",
    "df['gap_days'] = (df['next_start_date'] - df['drug_exposure_end_date']).dt.days\n",
    "\n",
    "# 30일 이상 중단된 경우 식별\n",
    "df['discontinued'] = df['gap_days'] > 30\n",
    "\n",
    "# 계속 복용한 경우 필터링\n",
    "df_continued = df[~df['discontinued'] | df['gap_days'].isna()]\n",
    "\n",
    "# 계속 복용한 데이터 저장\n",
    "df_continued.to_csv('medication_continued.csv', index=False)\n",
    "\n",
    "print(\"계속 복용한 데이터가 'medication_continued.csv' 파일에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계속 복용한 데이터가 'medication_continued_by_drug_filtered.csv' 파일에 저장되었습니다.\n",
      "중단된 데이터가 'medication_discontinued_by_drug.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 파일 경로\n",
    "file_path = 'tofdrug2_drug_filtered_categorized.csv'\n",
    "\n",
    "# 최소 복용 일수 설정 (예: 3일)\n",
    "min_duration_days = 3\n",
    "# 최대 허용 중단 간격 (예: 30일)\n",
    "max_gap_days = 30\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 날짜 컬럼을 datetime 형식으로 변환\n",
    "df['drug_exposure_start_date'] = pd.to_datetime(df['drug_exposure_start_date'])\n",
    "df['drug_exposure_end_date'] = pd.to_datetime(df['drug_exposure_end_date'])\n",
    "\n",
    "# 데이터프레임을 person_id, drug_source_value, drug_exposure_start_date 기준으로 정렬\n",
    "df = df.sort_values(by=['person_id', 'drug_source_value', 'drug_exposure_start_date'])\n",
    "\n",
    "# 연속된 처방 기록을 그룹화하여 단일 복용 기간으로 처리\n",
    "df['prev_end_date'] = df.groupby(['person_id', 'drug_source_value'])['drug_exposure_end_date'].shift(1)\n",
    "df['new_period'] = (df['drug_exposure_start_date'] - df['prev_end_date']).dt.days > 1\n",
    "df['group_id'] = df.groupby(['person_id', 'drug_source_value'])['new_period'].cumsum()\n",
    "\n",
    "# 그룹화하여 새로운 복용 기간 계산\n",
    "grouped_df = df.groupby(['person_id', 'drug_source_value', 'group_id', 'drug_category']).agg({\n",
    "    'drug_exposure_start_date': 'min',\n",
    "    'drug_exposure_end_date': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# 복용 기간 계산\n",
    "grouped_df['duration_days'] = (grouped_df['drug_exposure_end_date'] - grouped_df['drug_exposure_start_date']).dt.days + 1\n",
    "\n",
    "# 다음 복용 기간의 시작 날짜 계산\n",
    "grouped_df = grouped_df.sort_values(by=['person_id', 'drug_source_value', 'drug_exposure_start_date'])\n",
    "grouped_df['next_start_date'] = grouped_df.groupby(['person_id', 'drug_source_value'])['drug_exposure_start_date'].shift(-1)\n",
    "grouped_df['gap_days'] = (grouped_df['next_start_date'] - grouped_df['drug_exposure_end_date']).dt.days\n",
    "\n",
    "# 계속 복용한 경우 필터링 (중단 간격이 30일 이하이고 최소 복용 기간을 충족)\n",
    "df_continued = grouped_df[(grouped_df['gap_days'] <= max_gap_days) & (grouped_df['duration_days'] >= min_duration_days) | grouped_df['gap_days'].isna()]\n",
    "\n",
    "# 중단된 경우 필터링 (중단 간격이 30일 초과하거나 최소 복용 기간을 충족하지 않음)\n",
    "df_discontinued = grouped_df[(grouped_df['gap_days'] > max_gap_days) | (grouped_df['duration_days'] < min_duration_days)]\n",
    "\n",
    "# 계속 복용한 데이터 저장\n",
    "output_file_continued = 'medication_continued_by_drug_filtered.csv'\n",
    "df_continued.to_csv(output_file_continued, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 중단된 데이터 저장\n",
    "output_file_discontinued = 'medication_discontinued_by_drug.csv'\n",
    "df_discontinued.to_csv(output_file_discontinued, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"계속 복용한 데이터가 '{output_file_continued}' 파일에 저장되었습니다.\")\n",
    "print(f\"중단된 데이터가 '{output_file_discontinued}' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결합된 데이터가 'cohort_ecg_final.csv' 파일에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로\n",
    "medication_file_path = 'cohort_ecg_final.csv'\n",
    "cohort_file_path = 'cohort_final2.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "medication_df = pd.read_csv(medication_file_path)\n",
    "cohort_df = pd.read_csv(cohort_file_path)\n",
    "\n",
    "# 필요한 컬럼만 선택 (person_id, AF, VT)\n",
    "cohort_df = cohort_df[['person_id', 'AF', 'VT']]\n",
    "\n",
    "# 데이터 병합 (person_id 기준)\n",
    "merged_df = pd.merge(medication_df, cohort_df, on='person_id', how='left')\n",
    "\n",
    "# 결과 저장\n",
    "output_file_path = 'cohort_ecg_final.csv'\n",
    "merged_df.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"결합된 데이터가 '{output_file_path}' 파일에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique Value</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOF</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TOF</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TOF, CATCH 22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TOF, absent pulmonary valve syndrome</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOF, CATCH22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TOF, nonsustained AT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TOF, dextrocardia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DORV, fallot</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TOF, Down syndrome</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TOF, multiple anomaly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DORV (Fallot type)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TOF, single coronary a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TOF, AP window</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TOF, PDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TOF, situs inversus, preterm, 33+4wks, 1.8kg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TOF ¾Æ»ê¿¡¼­ total</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TOF, Rt aortic arch, ALSA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TOF, interrupted LPA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TOF, interrupted LPA, CATCH22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TOF, nonsustained VT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TOF, bilateral SVC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TOF (¼ö¼ú ±â·Ï PV nearly atresia), 03-04-23 ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TOF, absent pul. Valve</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TOF, r/o CATCH 22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TOF with hypoplastic PA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fallot type DORV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>absent PV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Unique Value  Count\n",
       "0                                                 TOF    334\n",
       "1                                                   1    198\n",
       "2                                                   2     45\n",
       "3                                                   3      8\n",
       "4                                                TOF       4\n",
       "5                                       TOF, CATCH 22      4\n",
       "6                TOF, absent pulmonary valve syndrome      3\n",
       "7                                        TOF, CATCH22      2\n",
       "8                                TOF, nonsustained AT      2\n",
       "9                                   TOF, dextrocardia      2\n",
       "10                                       DORV, fallot      2\n",
       "11                                 TOF, Down syndrome      2\n",
       "12                              TOF, multiple anomaly      1\n",
       "13                                 DORV (Fallot type)      1\n",
       "14                             TOF, single coronary a      1\n",
       "15                                     TOF, AP window      1\n",
       "16                                           TOF, PDA      1\n",
       "17       TOF, situs inversus, preterm, 33+4wks, 1.8kg      1\n",
       "18                                 TOF ¾Æ»ê¿¡¼­ total      1\n",
       "19                          TOF, Rt aortic arch, ALSA      1\n",
       "20                               TOF, interrupted LPA      1\n",
       "21                      TOF, interrupted LPA, CATCH22      1\n",
       "22                               TOF, nonsustained VT      1\n",
       "23                                 TOF, bilateral SVC      1\n",
       "24  TOF (¼ö¼ú ±â·Ï PV nearly atresia), 03-04-23 ca...      1\n",
       "25                             TOF, absent pul. Valve      1\n",
       "26                                  TOF, r/o CATCH 22      1\n",
       "27                            TOF with hypoplastic PA      1\n",
       "28                                   fallot type DORV      1\n",
       "29                                          absent PV      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Try reading with different encodings\n",
    "file_path = 'dx.csv'\n",
    "\n",
    "# Replace 'latin1' with other encodings if needed\n",
    "df = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# 'dx' 컬럼의 고유값들과 그 개수 확인\n",
    "value_counts = df['dx'].value_counts().reset_index()\n",
    "\n",
    "# 컬럼 이름 설정\n",
    "value_counts.columns = ['Unique Value', 'Count']\n",
    "\n",
    "value_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
