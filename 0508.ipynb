{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cohort_df = pd.read_csv('cohort_final.csv')\n",
    "tof_drug_df = pd.read_csv('tof_final_cohort_drug.csv')\n",
    "\n",
    "# 'person_id'를 기준으로 데이터 병합 (left join)\n",
    "merged_df = pd.merge(tof_drug_df, cohort_df[['person_id', 'tof_group']], on='person_id', how='left')\n",
    "\n",
    "# 결과 저장\n",
    "merged_df.to_csv('tof_final_cohort_drug_with_group.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tof_group\n",
       "3    925\n",
       "2    182\n",
       "1    140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "merged_df = pd.read_csv('tof_final_cohort_drug_with_group.csv')\n",
    "\n",
    "# 각 그룹별 고유 person_id 수 계산\n",
    "group_distinct_counts = merged_df.drop_duplicates(subset=['person_id'])['tof_group'].value_counts()\n",
    "\n",
    "group_distinct_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOF Total 계산 (group 1, 2, 3 모두 포함)\n",
    "tof_total = merged_df['person_id'].nunique()\n",
    "\n",
    "# 결과 출력\n",
    "tof_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "final_cohort_df = pd.read_csv('tof_final_cohort_drug_with_group.csv')\n",
    "\n",
    "# drug_source_value에 따라 새로운 컬럼 값 할당\n",
    "def map_drug_category(value):\n",
    "    diuretics = ['FRS4', 'SRN2', 'HCT']\n",
    "    raas = ['ENL', 'ENL5', 'LST100', 'LST25']\n",
    "    beta_blocker = ['CVD3', 'CVD6', 'CVD1', 'CVD', 'CVDS8', 'CVDS16', 'CVDS64', 'CVDS32']\n",
    "    antiplatelet = ['ASAT1', 'ASAE', 'ASA500', 'CPD', 'CPDN']\n",
    "    anticoagulation = ['WFR2', 'WFR5']\n",
    "    etc = ['SCBVS50', 'SCBVS100', 'SCBVS200', 'TVT15', 'TVT30', 'DPGZ']\n",
    "    class_i = ['FCND50', 'QND', 'MXLT', 'LDC2I', 'LDC1I', 'LDC2I5']\n",
    "    class_ii = ['NDL', 'ATN', 'ATN2', 'PPN1', 'PPN4', 'PPNS', 'MTP', 'BSPL', 'BSPL1K', 'BSPL2', 'BSPL10', 'CVD3', 'CVD6', 'CVD1', 'CVD', 'CVDS8', 'CVDS16', 'CVDS64', 'CVDS32']\n",
    "    class_iii = ['AMO', 'AMOI', 'STL4']\n",
    "    class_iv = ['VRP18', 'VRP4', 'VRP8', 'VRPI', 'DTA3IR', 'DTA3', 'DTA9', 'DTAI', 'DTA18']\n",
    "    miscellaneous = ['DGXL', 'DGX25', 'DGXI', 'ADN90I', 'ADNI']\n",
    "\n",
    "    if value in diuretics:\n",
    "        return 'diuretics'\n",
    "    elif value in raas:\n",
    "        return 'RAAS'\n",
    "    elif value in beta_blocker:\n",
    "        return 'beta blocker'\n",
    "    elif value in antiplatelet:\n",
    "        return 'antiplatelet'\n",
    "    elif value in anticoagulation:\n",
    "        return 'anticoagulation'\n",
    "    elif value in etc:\n",
    "        return 'etc'\n",
    "    elif value in class_i:\n",
    "        return 'Class I'\n",
    "    elif value in class_ii:\n",
    "        return 'Class II'\n",
    "    elif value in class_iii:\n",
    "        return 'Class III'\n",
    "    elif value in class_iv:\n",
    "        return 'Class IV'\n",
    "    elif value in miscellaneous:\n",
    "        return 'miscellaneous'\n",
    "    else:\n",
    "        return None  # 또는 'Other'를 반환할 수도 있습니다.\n",
    "\n",
    "# 새 컬럼 생성\n",
    "final_cohort_df['drug_category'] = final_cohort_df['drug_source_value'].apply(map_drug_category)\n",
    "\n",
    "# 결과 데이터 확인\n",
    "final_cohort_df.head()\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "final_cohort_df.to_csv('tof_final_cohort_drug_with_group_and_category.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "ecg_data = pd.read_csv('tof_ecg.csv')\n",
    "cohort_data = pd.read_csv('cohort_final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>measurement_date</th>\n",
       "      <th>VentricularRate</th>\n",
       "      <th>PRInterval</th>\n",
       "      <th>QRSDuration</th>\n",
       "      <th>QTInterval</th>\n",
       "      <th>QTCorrected</th>\n",
       "      <th>Paxis</th>\n",
       "      <th>Raxis</th>\n",
       "      <th>Taxis</th>\n",
       "      <th>Qonset</th>\n",
       "      <th>Qoffset</th>\n",
       "      <th>Ponset</th>\n",
       "      <th>Poffset</th>\n",
       "      <th>QTcFrederica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      person_id measurement_date  VentricularRate  PRInterval  QRSDuration  \\\n",
       "1549        NaN              NaT              NaN         NaN          NaN   \n",
       "1550        NaN              NaT              NaN         NaN          NaN   \n",
       "1551        NaN              NaT              NaN         NaN          NaN   \n",
       "1552        NaN              NaT              NaN         NaN          NaN   \n",
       "1553        NaN              NaT              NaN         NaN          NaN   \n",
       "\n",
       "      QTInterval  QTCorrected  Paxis  Raxis  Taxis  Qonset  Qoffset  Ponset  \\\n",
       "1549         NaN          NaN    NaN    NaN    NaN     NaN      NaN     NaN   \n",
       "1550         NaN          NaN    NaN    NaN    NaN     NaN      NaN     NaN   \n",
       "1551         NaN          NaN    NaN    NaN    NaN     NaN      NaN     NaN   \n",
       "1552         NaN          NaN    NaN    NaN    NaN     NaN      NaN     NaN   \n",
       "1553         NaN          NaN    NaN    NaN    NaN     NaN      NaN     NaN   \n",
       "\n",
       "      Poffset  QTcFrederica  \n",
       "1549      NaN           NaN  \n",
       "1550      NaN           NaN  \n",
       "1551      NaN           NaN  \n",
       "1552      NaN           NaN  \n",
       "1553      NaN           NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date columns to datetime type for proper comparison and manipulation\n",
    "ecg_data['measurement_date'] = pd.to_datetime(ecg_data['measurement_date'])\n",
    "cohort_data['condition_start_date'] = pd.to_datetime(cohort_data['condition_start_date'])\n",
    "\n",
    "# Adjust the return statement for missing data case to include the correct number of None for all columns\n",
    "def get_closest_measurement(row):\n",
    "    # Filter ECG records for the same person\n",
    "    person_measurements = ecg_data[ecg_data['person_id'] == row['person_id']]\n",
    "    # Filter out measurements before the condition start date\n",
    "    valid_measurements = person_measurements[person_measurements['measurement_date'] >= row['condition_start_date']]\n",
    "    # Find the measurement closest to the condition start date\n",
    "    if not valid_measurements.empty:\n",
    "        closest_measurement = valid_measurements.loc[valid_measurements['measurement_date'].idxmin()]\n",
    "        return closest_measurement\n",
    "    else:\n",
    "        return pd.Series([None] * len(ecg_data.columns), index=ecg_data.columns)\n",
    "\n",
    "# Apply the function to each row in cohort data and join the results as new columns\n",
    "closest_measurements = cohort_data.apply(get_closest_measurement, axis=1)\n",
    "closest_measurements.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the closest measurements to the cohort dataframe\n",
    "augmented_cohort_data = cohort_data.join(closest_measurements, rsuffix='_ecg')\n",
    "\n",
    "# Show the columns and first few rows of the updated dataframe to verify the join\n",
    "augmented_cohort_data.head(), augmented_cohort_data.columns\n",
    "\n",
    "# Save the augmented cohort data to a new CSV file\n",
    "augmented_cohort_data.to_csv('cohort_final_ecg.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터 로드\n",
    "cohort_data = pd.read_csv('cohort_final.csv')\n",
    "cohort_ecg2_data = pd.read_csv('cohort_final_ecg2.csv')\n",
    "\n",
    "# cohort_final_ecg2.csv에 있는 person_id 추출\n",
    "ecg2_person_ids = cohort_ecg2_data['person_id'].unique()\n",
    "\n",
    "# cohort_final.csv에서 cohort_final_ecg2.csv에 있는 person_id만 남기기\n",
    "filtered_cohort_data = cohort_data[cohort_data['person_id'].isin(ecg2_person_ids)]\n",
    "\n",
    "# 결과를 새 CSV 파일로 저장\n",
    "filtered_cohort_data.to_csv('cohort_final2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
